{"cells":[{"cell_type":"code","source":["\"\"\"\n","Bronze Layer: Raw Data Ingestion\n","Purpose: Load CSV file into Bronze layer with zero transformations\n","Requirements: Preserve original schema, validate row count and basic integrity\n","\"\"\"\n","\n","from pyspark.sql.functions import input_file_name, current_timestamp, col, trim\n","\n","# Step 1: Load raw CSV file with original schema preserved\n","#inferSchema=false: Keep all columns as strings\n","df_raw = spark.read.format(\"csv\") \\\n","    .option(\"header\", \"true\") \\\n","    .option(\"inferSchema\", \"false\") \\\n","    .option(\"encoding\", \"UTF-8\") \\\n","    .load(\"Files/bronze/house-price-timeseries.csv\")\n","\n","# Step 2: Add technical metadata columns\n","df_bronze = df_raw \\\n","    .withColumn(\"_source_file\", input_file_name()) \\\n","    .withColumn(\"_ingestion_time\", current_timestamp()) \\\n","    .withColumn(\"_batch_id\", current_timestamp().cast(\"string\"))\n","\n","# Step 3: Validate row count and basic integrity (no truncation)\n","initial_row_count = df_bronze.count()\n","print(f\"Total rows loaded: {initial_row_count}\")\n","\n","# Check critical columns for null values to detect truncation\n","critical_columns = [\"property_id\", \"price\", \"month\"]\n","for column in critical_columns:\n","    if column in df_bronze.columns:\n","        null_count = df_bronze.filter(col(column).isNull() | (trim(col(column)) == \"\")).count()\n","        print(f\"{column} null/empty count: {null_count}\")\n","\n","# Step 4: Save to Bronze layer as Delta table\n","bronze_table_name = \"houses_price_bronze\"\n","df_bronze.write \\\n","    .mode(\"overwrite\") \\\n","    .format(\"delta\") \\\n","    .saveAsTable(bronze_table_name)\n","\n","print(f\"Bronze table saved: {bronze_table_name} with {initial_row_count} rows\")\n","print(\"All columns preserved as string type, no transformations applied\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":3,"statement_ids":[3],"state":"finished","livy_statement_state":"available","session_id":"85978354-5040-4a55-a44e-3b70e36861e7","normalized_state":"finished","queued_time":"2026-01-09T04:21:24.3090778Z","session_start_time":"2026-01-09T04:21:24.3100796Z","execution_start_time":"2026-01-09T04:21:36.4271871Z","execution_finish_time":"2026-01-09T04:21:53.3567686Z","parent_msg_id":"1ceb71b4-2f19-4ac1-b13c-d5161add0aac"},"text/plain":"StatementMeta(, 85978354-5040-4a55-a44e-3b70e36861e7, 3, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Total rows loaded: 19620\nproperty_id null/empty count: 0\nprice null/empty count: 0\nmonth null/empty count: 0\nBronze table saved: houses_price_bronze with 19620 rows\nAll columns preserved as string type, no transformations applied\n"]}],"execution_count":1,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"2ee36567-06eb-475a-9c09-81c6d222ccaa"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","display_name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{"known_lakehouses":[{"id":"ce3b5fc7-ecbf-4ad1-92dd-2c8b293c16dc"}],"default_lakehouse":"ce3b5fc7-ecbf-4ad1-92dd-2c8b293c16dc","default_lakehouse_name":"lh_house_pricing","default_lakehouse_workspace_id":"9c88270a-3281-4af9-8314-5f89575d7662"}}},"nbformat":4,"nbformat_minor":5}